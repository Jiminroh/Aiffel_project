# Exploration 1. ì¸ê³µì§€ëŠ¥ê³¼ ê°€ìœ„ë°”ìœ„ë³´ í•˜ê¸°

# 1-1 . ì¸ê³µì§€ëŠ¥ê³¼ ê°€ìœ„ë°”ìœ„ë³´ í•˜ê¸°

ì‚¬ì „ ìˆœì„œ 

<aside>
ğŸ’¡ ë°ì´í„° ì¤€ë¹„ â†’ ë”¥ëŸ¬ë‹ ë„¤íŠ¸ì›Œí¬ ì„¤ê³„ â†’ í•™ìŠµ â†’ í…ŒìŠ¤íŠ¸(í‰ê°€)

</aside>

# 1-2. ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ì!

mnist data

```python
import tensorflow as tf
from tensorflow import keras

import numpy as np
import matplotlib.pyplot as plt
import os

print(tf.__version__)   # Tensorflowì˜ ë²„ì „ì„ ì¶œë ¥

mnist = keras.datasets.mnist

# MNIST ë°ì´í„°ë¥¼ ë¡œë“œ. ë‹¤ìš´ë¡œë“œí•˜ì§€ ì•Šì•˜ë‹¤ë©´ ë‹¤ìš´ë¡œë“œê¹Œì§€ ìë™ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤. 
(x_train, y_train), (x_test, y_test) = mnist.load_data()   

```

<aside>
ğŸ’¡ MINST data?
í¬ê¸° â†’ 28x28í¬ê¸°ì˜ train ë°ì´í„° 60000ì¥,  test 10000ì¥
êµ¬ì„± â†’ x_train : ì´ë¯¸ì§€

            y_train : x_trainì— ëŒ€í•œ ì •ë‹µ

      x_test : test ì´ë¯¸ì§€

y_test : x_testì— ëŒ€í•œ ì •ë‹µ 

</aside>

### validation set

<aside>
ğŸ’¡ validation setì´ë€?
ì´ë¯¸ í•™ìŠµëœ setì´ë©° ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ê³¼ì •ì´ ì •ìƒì ìœ¼ë¡œ ì§„í–‰ë˜ê³  ìˆëŠ”ì§€, ì˜¤ë²„í”¼íŒ…ì´ ë°œìƒí•˜ê³  ìˆì§€ ì•Šì€ì§€. í•™ìŠµì„ ì¤‘ë‹¨í•´ë„ ë˜ëŠ”ì§€ ë“±ì„ í™•ì¸í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©

</aside>

### ë°ì´í„° ì „ì²˜ë¦¬ í•˜ê¸°

ì •ê·œí™” í•˜ê¸°

```python
x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0
```

# 1-3. ë”¥ëŸ¬ë‹ ë„¤íŠ¸ì›Œí¬ ì„¤ê³„í•˜ê¸°

í…ì„œí”Œë¡œìš° ì¼€ë¼ìŠ¤ì˜ Sequential API í™œìš©

```python
model=keras.models.Sequential()
model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,1)))
model.add(keras.layers.MaxPool2D(2,2))
model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))
model.add(keras.layers.MaxPooling2D((2,2)))
model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(32, activation='relu'))
model.add(keras.layers.Dense(10, activation='softmax'))

print('Modelì— ì¶”ê°€ëœ Layer ê°œìˆ˜: ', len(model.layers))
# >>> Modelì— ì¶”ê°€ëœ Layer ê°œìˆ˜: 7 

model.summary() # ëª¨ë¸ í™•ì¸
```

![Untitled](images/1-1.png)

![Untitled](images/1-2.png)

# 1-4.ë”¥ëŸ¬ë‹ ë„¤íŠ¸ì›Œí¬ í•™ìŠµì‹œí‚¤ê¸°

### reshape

```python
print("Before Reshape - x_train_norm shape: {}".format(x_train_norm.shape))
print("Before Reshape - x_test_norm shape: {}".format(x_test_norm.shape))

# ë°ì´í„°ê°¯ìˆ˜ì— -1ì„ ì“°ë©´ reshapeì‹œ ìë™ê³„ì‚°ë©ë‹ˆë‹¤.
x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 1)  
x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 1)

print("After Reshape - x_train_reshaped shape: {}".format(x_train_reshaped.shape))
print("After Reshape - x_test_reshaped shape: {}".format(x_test_reshaped.shape))

# >>>
# Before Reshape - x_train_norm shape: (60000, 28, 28)
# Before Reshape - x_test_norm shape: (10000, 28, 28)
# After Reshape - x_train_reshaped shape: (60000, 28, 28, 1)
# After Reshape - x_test_reshaped shape: (10000, 28, 28, 1)
```

### í•™ìŠµ ì‹œí‚¤ê¸°

```python
model.compile(optimizer='adam',
             loss='sparse_categorical_crossentropy',
             metrics=['accuracy'])

model.fit(x_train_reshaped, y_train, epochs=10)
```

# 1-5. ì–¼ë§ˆë‚˜ ì˜ ë§Œë“¤ë €ëŠ”ì§€ í™•ì¸í•˜ê¸°

### ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í•˜ê¸°

```python
test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)
print("test_loss: {} ".format(test_loss))
print("test_accuracy: {}".format(test_accuracy))
```

### ì˜ ëª» ëœ ë°ì´í„° í™•ì¸

```python
predicted_result = model.predict(x_test_reshaped)  # modelì´ ì¶”ë¡ í•œ í™•ë¥ ê°’. 
predicted_labels = np.argmax(predicted_result, axis=1)

idx=0  #1ë²ˆì§¸ x_testë¥¼ ì‚´í´ë³´ì. 
print('model.predict() ê²°ê³¼ : ', predicted_result[idx])
print('modelì´ ì¶”ë¡ í•œ ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ê²°ê³¼ : ', predicted_labels[idx])
print('ì‹¤ì œ ë°ì´í„°ì˜ ë¼ë²¨ : ', y_test[idx])
```

```python
import random
wrong_predict_list=[]
for i, _ in enumerate(predicted_labels):
    # ië²ˆì§¸ test_labelsê³¼ y_testì´ ë‹¤ë¥¸ ê²½ìš°ë§Œ ëª¨ì•„ ë´…ì‹œë‹¤. 
    if predicted_labels[i] != y_test[i]:
        wrong_predict_list.append(i)

# wrong_predict_list ì—ì„œ ëœë¤í•˜ê²Œ 5ê°œë§Œ ë½‘ì•„ë´…ì‹œë‹¤.
samples = random.choices(population=wrong_predict_list, k=5)

for n in samples:
    print("ì˜ˆì¸¡í™•ë¥ ë¶„í¬: " + str(predicted_result[n]))
    print("ë¼ë²¨: " + str(y_test[n]) + ", ì˜ˆì¸¡ê²°ê³¼: " + str(predicted_labels[n]))
    plt.imshow(x_test[n], cmap=plt.cm.binary)
    plt.show()
```

# 1-6. ë” ì¢‹ì€ ë„¤íŠ¸ì›Œí¬ ë§Œë“¤ì–´ ë³´ê¸°

### í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ ë³€í™”ì‹œì¼œ ì„±ëŠ¥ í™•ì¸

```python
# ë°”ê¿” ë³¼ ìˆ˜ ìˆëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤
n_channel_1=16
n_channel_2=64
n_dense=64
n_train_epoch=10

model=keras.models.Sequential()
model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,1)))
model.add(keras.layers.MaxPool2D(2,2))
model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))
model.add(keras.layers.MaxPooling2D((2,2)))
model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(n_dense, activation='relu'))
model.add(keras.layers.Dense(10, activation='softmax'))

model.summary()
model.compile(optimizer='adam',
             loss='sparse_categorical_crossentropy',
             metrics=['accuracy'])

# ëª¨ë¸ í›ˆë ¨
model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)

# ëª¨ë¸ ì‹œí—˜
test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)
print("test_loss: {} ".format(test_loss))
print("test_accuracy: {}".format(test_accuracy))
```